{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN//AOC43VgpqcfnhfO9FX1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abishekrz/WebScraping-AI-ML/blob/main/Assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEvnJRNvm6Jj",
        "outputId": "bb1221e5-86f3-423c-d55c-aeca81f46d02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vteLeonardo DiCaprio\n",
            "Year(s)\n",
            "\n",
            "Year\n",
            "\n",
            "Year\n",
            "\n",
            "Whose Vote Counts, Explained\n",
            "\n",
            "What's Eating Gilbert Grape\n",
            "\n",
            "Virunga\n",
            "\n",
            "Total Eclipse\n",
            "\n",
            "Title\n",
            "\n",
            "Title\n",
            "\n",
            "Title\n",
            "\n",
            "Titanic\n",
            "\n",
            "This Boy's Life\n",
            "\n",
            "Theodore Roosevelt\n",
            "\n",
            "The Wolf of Wall Street\n",
            "\n",
            "The Wolf of Wall Street\n",
            "\n",
            "The Titans That Built America\n",
            "\n",
            "The Right Stuff\n",
            "\n",
            "The Revenant\n",
            "\n",
            "The Quick and the Dead\n",
            "\n",
            "The Outsiders\n",
            "\n",
            "The New Lassie\n",
            "\n",
            "The Mickey Mouse Club\n",
            "\n",
            "The Men Who Built America: Frontiersmen\n",
            "\n",
            "The Man in the Iron Mask\n",
            "\n",
            "The Loneliest Whale: The Search for 52\n",
            "\n",
            "The Ivory Game\n",
            "\n",
            "The Ides of March\n",
            "\n",
            "The Departed\n",
            "\n",
            "The Beach\n",
            "\n",
            "The Basketball Diaries\n",
            "\n",
            "The Aviator\n",
            "\n",
            "The Aviator\n",
            "\n",
            "The Audition\n",
            "\n",
            "The Assassination of Richard Nixon\n",
            "\n",
            "The 11th Hour\n",
            "\n",
            "The 11th Hour\n",
            "\n",
            "Struggle: The Life and Lost Art of Szukalski\n",
            "\n",
            "Shutter Island\n",
            "\n",
            "Screenwriter\n",
            "Saturday Night Live\n",
            "\n",
            "Santa Barbara\n",
            "\n",
            "Runner Runner\n",
            "\n",
            "Roseanne\n",
            "\n",
            "Romeo + Juliet\n",
            "\n",
            "Role\n",
            "\n",
            "Role\n",
            "\n",
            "Robin Hood\n",
            "\n",
            "Richard Jewell\n",
            "\n",
            "Revolutionary Road\n",
            "\n",
            "Related\n",
            "Ref.\n",
            "\n",
            "Ref.\n",
            "\n",
            "Ref.\n",
            "\n",
            "Red Riding Hood\n",
            "\n",
            "Producer\n",
            "Poison Ivy\n",
            "\n",
            "Parenthood\n",
            "\n",
            "Out of the Furnace\n",
            "\n",
            "Orphan\n",
            "\n",
            "Once Upon a Time in Hollywood\n",
            "\n",
            "Notes\n",
            "\n",
            "Notes\n",
            "\n",
            "Marvin's Room\n",
            "\n",
            "Live by Night\n",
            "\n",
            "Killers of the Flower Moon\n",
            "\n",
            "Killers of the Flower Moon\n",
            "\n",
            "Kid 90\n",
            "\n",
            "J. Edgar\n",
            "\n",
            "Inception\n",
            "\n",
            "Ice on Fire\n",
            "\n",
            "Hubble\n",
            "\n",
            "Growing Pains\n",
            "\n",
            "Greensburg\n",
            "\n",
            "Grant\n",
            "\n",
            "Gardener of Eden\n",
            "\n",
            "Gangs of New York\n",
            "\n",
            "Fin\n",
            "\n",
            "Don't Look Up\n",
            "\n",
            "Django Unchained\n",
            "\n",
            "Delirium\n",
            "\n",
            "Critters 3\n",
            "\n",
            "Credit\n",
            "\n",
            "Cowspiracy\n",
            "\n",
            "Celebrity\n",
            "\n",
            "Catching the Sun\n",
            "\n",
            "Catch Me If You Can\n",
            "\n",
            "Body of Lies\n",
            "\n",
            "Blood Diamond\n",
            "\n",
            "Before the Flood\n",
            "\n",
            "Before the Flood\n",
            "\n",
            "And We Go Green\n",
            "\n",
            " The Great Gatsby\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "url = \"https://en.wikipedia.org/wiki/Leonardo_DiCaprio_filmography\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "movie_titles = soup.select(\"th\",class_='class=\"headerSort headerSortUp\"')\n",
        "movies = []\n",
        "for movie_title in movie_titles:\n",
        "  movies.append(movie_title.text)\n",
        "movies = [movie for movie in movies if movie]\n",
        "movies.sort(reverse=True)\n",
        "for movie in movies:\n",
        "  print(movie)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/kepler_data .csv')  # Assuming 'kepler_data.csv' contains the dataset\n",
        "X = data.drop(columns=['koi_disposition'])\n",
        "y = data['koi_disposition']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y5AOG-w_2Jyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the Random Forest algorithm for several reasons:\n",
        "\n",
        "Robustness to overfitting: Random Forest tends to handle overfitting well compared to other algorithms like Decision Trees, making it a suitable choice for classification tasks.\n",
        "\n",
        "Flexibility and ease of use: Random Forest doesn't require extensive hyperparameter tuning and preprocessing compared to some other algorithms, making it easy to implement and get started with.\n",
        "\n",
        "Feature importance: Random Forest provides a feature importance score, which can be useful for understanding the relative importance of different features in the classification process.\n",
        "\n",
        "Different tuning methods used for Random Forest include:\n",
        "\n",
        "Number of trees (n_estimators): The number of trees in the forest. Generally, higher numbers tend to perform better, but it comes with increased computational cost.\n",
        "\n",
        "Maximum depth of trees (max_depth): The maximum depth of the tree. Deeper trees may lead to overfitting, so this parameter can help control the complexity of the model.\n",
        "\n",
        "Minimum number of samples required to split a node (min_samples_split): This parameter helps control overfitting by setting a threshold for the number of samples required to split a node further.\n",
        "\n",
        "Minimum number of samples required at each leaf node (min_samples_leaf): Similar to min_samples_split, but this parameter controls the minimum number of samples required at each leaf node.\n",
        "\n",
        "Feature subsampling (max_features): The number of features to consider when looking for the best split. It can help reduce overfitting by forcing each tree to consider only a random subset of features.\n",
        "\n",
        "Other algorithms considered could include Support Vector Machines (SVMs), Gradient Boosting Machines, or Neural Networks. However, Random Forest was chosen due to its simplicity, robustness, and good performance in many classification tasks.\n",
        "\n",
        "The accuracy of the model can be obtained using the accuracy_score function from the sklearn.metrics module after making predictions on the test set.\n",
        "\n",
        "Different types of metrics that can be used to evaluate the model include:\n",
        "\n",
        "Accuracy: Ratio of correctly predicted observations to the total observations.\n",
        "\n",
        "Precision: Proportion of true positive predictions among all positive predictions. Precision = TP / (TP + FP)\n",
        "\n",
        "Recall (Sensitivity): Proportion of true positive predictions among all actual positives. Recall = TP / (TP + FN)\n",
        "\n",
        "F1 Score: Harmonic mean of precision and recall. F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
        "\n",
        "Confusion Matrix: A table showing the counts of true positive, true negative, false positive, and false negative predictions.\n",
        "\n",
        "ROC Curve and AUC: Receiver Operating Characteristic curve and Area Under the Curve, which measure the trade-off between true positive rate and false positive rate.\n",
        "\n",
        "Cross-validation scores: Average performance of the model across different train-test splits, providing more robust evaluation.\n"
      ],
      "metadata": {
        "id": "lVHXTUpH_j4k"
      }
    }
  ]
}